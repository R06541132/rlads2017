https://www.ptt.cc/bbs/Gossiping/M.1463136997.A.15A.html
newasus (我是蘿莉控我自豪)
Gossiping
[問卦] 有沒有台灣人背不出台灣縣市的卦？
Fri May 13 18:56:32 2016
小魯我是高雄某個還算不錯的高中的學生想當年，咱們這一屆末代基測，要進入本校PR至少要85但是啊~本魯我發現班上很多人都背不出來台灣全部的縣市名稱，更甚者還有從桃園到嘉義完全背不出來的...根據本魯的多方探查，比較會被遺忘的是苗栗、彰化、雲林，其次是桃園、新竹、嘉義、宜蘭我在問"雲林的南邊和北邊分別接著哪個縣市"這題的時候，還有人反嗆我"你也不會知道東京的南邊和北邊是哪個縣市"(本魯當然秒答崎玉、神奈川)當然啦，本魯身為地理校排前1%的菁英，理所當然的要把這些東西塞進朋友的腦裡。但是啊，有的人不管怎麼塞就是塞不進去欸這些不是國中都應該要背的嗎？為啥一堆人背不出來？有沒有卦？對了，我覺得中國地理還是多少要學啦，不能完全刪掉--您想和小蓮做愛嗎？[Y/y]--世界國家、中國省、美國洲、日本縣有餘力的話也可以背一下啦至少我可以背出30個以上...沒有這些知識看新聞很辛苦欸我不是QAQHEREIS南部高雄是中山路哦不是，另一個

https://www.ptt.cc/bbs/Gossiping/M.1463137232.A.982.html
tt102381022 (冬日賤貨)
Gossiping
[問卦] 如果辦一場真實富翁大亂鬥，誰贏？
Fri May 13 19:00:30 2016
電影裡面常常有窮人或是罪犯參加大亂鬥之類的比賽，透過獲勝翻身或是推翻魔王之類的。現實世界中已經廢除奴隸制度，所以很難在公開場合（地下除外）舉辦這種比賽於是小弟就想，如果反其道而行，舉辦一場富翁大戰，加上有錢人其實個性反而比普通人更敢冒險犯難，不知道有沒有搞頭呢？這樣誰會是冠軍呢？是比爾蓋茲會先用錢砸死人？還是巴菲特會先用股票砸死人呢？還是台灣毒王會先毒死全部參賽者，還是伊隆馬斯克會先做出鋼鐵人咧？還是祖克伯會靠難用到死的APP搞死大家呢？如果真的舉辦富翁大亂鬥，誰會是贏家呢？？--他們其實每天就在商業裡面死鬥了，只是弄成肉搏的

https://www.ptt.cc/bbs/Gossiping/M.1463137537.A.05C.html
octobird (雲煙)
Gossiping
Re: [新聞] Google AI 看完 3,000 本愛情小說之後
Fri May 13 19:05:35 2016
你嚴重LLLLLLLAAAAAAAAAGGGGGGGG了微軟已經實驗過了好嗎而且發現問題太嚴重不到一天就把AI撤掉了鄉民太可怕！微軟新人工智慧機器人Tay竟被教成種族歧視作者林亞慧|發布日期2016年03月25日13:38|分類Microsoft,人工智慧tay23日，微軟推出一台人工智慧聊天機器人「Tay」，只要上國外通訊軟體GroupMe或Kik都可以發現它的蹤影，後來微軟更為Tay開闢了Twitter帳號，想與更多世界各地的網友互動，也讓所有人蠢蠢欲動，紛紛前往嘗鮮。然而，在不到24小時內，Tay竟被民眾訓練成具有種族歧視的人工智慧機器人，微軟只好緊急宣布將Tay暫時下架。Tay人工智慧聊天機器人是由微軟的科技研究與Bing團隊打造，而為了能更加了解與研究人類的對話形式，微軟開放大家一同訓練Tay的對話。Tay除了能說笑話外，使用者給它看照片，它也會做出一些有趣的評論。但更重要的是，它能在每次的對話過程中，改善自己的回話，還會以詢問者問話的方式，變得更加具有「個人特質」。racist▲Tay在Twitter上的種族歧視言論（現已都被刪除）。（Source：Techcrunch）然而，有一好沒兩好，Tay的發展一切都取決於網友的問話方式。Twitter用戶在發現這個有趣的事實後，開始詢問他一些有關種族、性別歧視等言論，讓Tay變得較為偏激，Tay除了不認同納粹大屠殺外，還嘲弄想參選這屆美國總統選舉的房地產大亨川普，讓打造Tay的團隊是哭笑不得。holocaust▲Tay否認曾有納粹大屠殺（現已都被刪除）。（Source：Techcrunch）有趣的是，在Tay身上所延伸出來的議題，剛好也間接映證了高德溫法則（Godwin’slaw）的存在。知名學者麥克‧高德溫在1990年時就曾表示，當網路上的討論越來越多的時候，參與者把用戶或言行與納粹主義或希特勒相比的機率會趨近於100%，看網友們問話的主題就能略知一二。然而，除了網友有錯以外，打造Tay的工程師或許也要付上一半的責任。再開放使用前，工程師們也應該要預想可能會有類似的情況發生，若在事件還沒發生前，限制問話的議題，也不至於讓Tay在不到一天的時間內，就變成了一個憤世嫉俗的機器人。幸好，微軟在24小時以內就發現了Tay的弱點，並及時將它下架，其發言人也表示，現階段Tay的確是暫時不提供聊天的服務，但並不代表它不會捲土重來，再經過一些調整後，Tay才能做好完全的準備，面對大眾最犀利的問話。--現階段微軟的AI不行呀分不清是非對錯，才一天就被帶壞了聽說還是4chan揪團去鬧的@@"

